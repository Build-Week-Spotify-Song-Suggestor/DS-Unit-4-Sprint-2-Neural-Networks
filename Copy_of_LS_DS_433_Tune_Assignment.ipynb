{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of LS_DS_433_Tune_Assignment.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "nteract": {
      "version": "0.22.4"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGGrt9EYlCqY"
      },
      "source": [
        "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
        "<br></br>\n",
        "<br></br>\n",
        "\n",
        "# Train Practice\n",
        "\n",
        "## *Data Science Unit 4 Sprint 2 Assignment 3*\n",
        "\n",
        "Continue to use TensorFlow Keras & a sample of the [Quickdraw dataset](https://github.com/googlecreativelab/quickdraw-dataset) to build a sketch classification model. The dataset has been sampled to only 10 classes and 10000 observations per class. Using your baseline model from yesterday, hyperparameter tune it and report on your highest validation accuracy. Your singular goal today is to achieve the highest accuracy possible.\n",
        "\n",
        "*Don't forgot to switch to GPU on Colab!*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptJ2b3wk62Ud"
      },
      "source": [
        "### Hyperparameters to Tune\n",
        "\n",
        "At a minimum, tune each of these hyperparameters using any strategy we discussed during lecture today: \n",
        "- Optimizer\n",
        "- Learning Rate\n",
        "- Activiation Function\n",
        "  - At least 1 subparameter within the Relu activation function\n",
        "- Number of Neurons in Hidden Layers\n",
        "- Number of Hidden Layers\n",
        "- Weight Initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "USXjs7Hk71Hy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0bb31725-0439-40bd-ddc0-76f508dedc96"
      },
      "source": [
        "# Your Code Starts Here\r\n",
        "\r\n",
        "\r\n",
        "# Imports\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "def load_quickdraw10(path):\r\n",
        "    # Load the data\r\n",
        "    df = np.load(path)\r\n",
        "    X = df['arr_0']\r\n",
        "    y = df['arr_1']\r\n",
        "\r\n",
        "    # Split the data\r\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\r\n",
        "        X, y, test_size=0.10, random_state=79, stratify=y\r\n",
        "    )\r\n",
        "\r\n",
        "    # Normalize the data\r\n",
        "    X_train = X_train.astype('float32') / 255\r\n",
        "    X_test = X_test.astype('float32') / 255\r\n",
        "\r\n",
        "    return X_train, y_train, X_test, y_test\r\n",
        "\r\n",
        "# Load my data\r\n",
        "X_train, y_train, X_test, y_test = load_quickdraw10('/content/quickdraw10.npz')\r\n",
        "\r\n",
        "# Check my work\r\n",
        "print(f'X Train: {X_train.shape},', f'y Train: {y_train.shape},', \r\n",
        "      f'X Test: {X_test.shape},', f'y Test: {y_test.shape}')\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X Train: (90000, 784), y Train: (90000,), X Test: (10000, 784), y Test: (10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zhynSz0a2hDd",
        "outputId": "8c853288-0219-43e6-9c61-5794767908f7"
      },
      "source": [
        "\r\n",
        "# Imports\r\n",
        "from tensorflow.keras import Sequential\r\n",
        "from tensorflow.keras.layers import Dense\r\n",
        "from tensorflow.keras.optimizers import Adam, SGD\r\n",
        "\r\n",
        "# Set up Baseline model from last assignment\r\n",
        "# Function to create a model\r\n",
        "def create_model(learn_rate=0.01, optimizer=SGD):\r\n",
        "    opt = optimizer(lr=learn_rate)\r\n",
        "    \r\n",
        "    # Instantiate the model\r\n",
        "    model = Sequential([\r\n",
        "                        Dense(128, input_dim=784, activation='sigmoid', \r\n",
        "                              name='Input_Layer'),\r\n",
        "                        Dense(64, activation='relu', name='Hidden_64'),\r\n",
        "                        Dense(32, activation='relu', name='Hidden_32'),\r\n",
        "                        Dense(10, activation='softmax', name='Output_Layer')\r\n",
        "    ])\r\n",
        "\r\n",
        "    # Compile the model\r\n",
        "    model.compile(loss='sparse_categorical_crossentropy',\r\n",
        "                  optimizer=opt,\r\n",
        "                  metrics=['accuracy'])\r\n",
        "    \r\n",
        "    return model\r\n",
        "\r\n",
        "# Create my default model and look a the summary\r\n",
        "base_model = create_model()\r\n",
        "base_model.summary()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "Input_Layer (Dense)          (None, 128)               100480    \n",
            "_________________________________________________________________\n",
            "Hidden_64 (Dense)            (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "Hidden_32 (Dense)            (None, 32)                2080      \n",
            "_________________________________________________________________\n",
            "Output_Layer (Dense)         (None, 10)                330       \n",
            "=================================================================\n",
            "Total params: 111,146\n",
            "Trainable params: 111,146\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-JqH8Iu2vKS",
        "outputId": "1c5e5e66-9cd7-4a32-cc4d-06b78d8f4de3"
      },
      "source": [
        "# Fit my model\r\n",
        "baseline = base_model.fit(X_train, y_train,\r\n",
        "                          epochs=15,\r\n",
        "                          validation_split=0.1)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "2532/2532 [==============================] - 7s 2ms/step - loss: 1.8114 - accuracy: 0.4166 - val_loss: 0.9890 - val_accuracy: 0.6930\n",
            "Epoch 2/15\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.9250 - accuracy: 0.7232 - val_loss: 0.8437 - val_accuracy: 0.7536\n",
            "Epoch 3/15\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.8264 - accuracy: 0.7547 - val_loss: 0.8028 - val_accuracy: 0.7641\n",
            "Epoch 4/15\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.7624 - accuracy: 0.7737 - val_loss: 0.7378 - val_accuracy: 0.7849\n",
            "Epoch 5/15\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.7278 - accuracy: 0.7842 - val_loss: 0.7143 - val_accuracy: 0.7888\n",
            "Epoch 6/15\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.6964 - accuracy: 0.7934 - val_loss: 0.6934 - val_accuracy: 0.7978\n",
            "Epoch 7/15\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.6689 - accuracy: 0.8022 - val_loss: 0.6829 - val_accuracy: 0.8006\n",
            "Epoch 8/15\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.6467 - accuracy: 0.8074 - val_loss: 0.6578 - val_accuracy: 0.8062\n",
            "Epoch 9/15\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.6382 - accuracy: 0.8095 - val_loss: 0.6531 - val_accuracy: 0.8076\n",
            "Epoch 10/15\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.6150 - accuracy: 0.8163 - val_loss: 0.6186 - val_accuracy: 0.8181\n",
            "Epoch 11/15\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.6006 - accuracy: 0.8211 - val_loss: 0.6312 - val_accuracy: 0.8148\n",
            "Epoch 12/15\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.5802 - accuracy: 0.8262 - val_loss: 0.6109 - val_accuracy: 0.8167\n",
            "Epoch 13/15\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.5745 - accuracy: 0.8272 - val_loss: 0.5860 - val_accuracy: 0.8274\n",
            "Epoch 14/15\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.5589 - accuracy: 0.8324 - val_loss: 0.5969 - val_accuracy: 0.8267\n",
            "Epoch 15/15\n",
            "2532/2532 [==============================] - 5s 2ms/step - loss: 0.5417 - accuracy: 0.8385 - val_loss: 0.5834 - val_accuracy: 0.8290\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r5xb6Wlq22rS",
        "outputId": "83be1f35-468a-4864-dca6-eac002e95159"
      },
      "source": [
        "base_model.evaluate(X_test, y_test)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 2ms/step - loss: 0.5955 - accuracy: 0.8208\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5954679846763611, 0.8208000063896179]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mrxR8gD23Bjn",
        "outputId": "d47415b1-28aa-4577-9581-8b351e5a2c1f"
      },
      "source": [
        "import numpy\r\n",
        "import pandas as pd\r\n",
        "from sklearn.model_selection import GridSearchCV\r\n",
        "from tensorflow.keras.models import Sequential\r\n",
        "from tensorflow.keras.layers import Dense\r\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\r\n",
        "\r\n",
        "# Function to create model, required for KerasClassifier\r\n",
        "def create_model2(units=128, layers=2):\r\n",
        "    # Create model\r\n",
        "    model = Sequential()\r\n",
        "    model.add(Dense(units, input_dim=784, activation='relu', name='Input_layer'))\r\n",
        "    \r\n",
        "    units = units/2\r\n",
        "\r\n",
        "    for num in range(layers):\r\n",
        "        model.add(Dense(units=units/2, activation='relu', \r\n",
        "                        name=f'Hidden_layer{(units/2)}'))\r\n",
        "        units = units/2\r\n",
        "\r\n",
        "    model.add(Dense(10, activation='softmax', name='Output_layer'))\r\n",
        "\r\n",
        "    opt = SGD(learning_rate=0.01)\r\n",
        "\r\n",
        "    # Compile model\r\n",
        "    model.compile(loss='sparse_categorical_crossentropy', \r\n",
        "                  optimizer=opt, metrics=['accuracy'])\r\n",
        "    return model\r\n",
        "\r\n",
        "# create model\r\n",
        "model = KerasClassifier(build_fn=create_model2, verbose=1)\r\n",
        "\r\n",
        "# define the grid search parameters\r\n",
        "param_grid = {'batch_size': [32,64,128],\r\n",
        "              'epochs': [5],\r\n",
        "              'units':[128]}\r\n",
        "# Create Grid Search\r\n",
        "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=2)\r\n",
        "grid_result = grid.fit(X_train, y_train)\r\n",
        "\r\n",
        "# Report Results\r\n",
        "print(f\"Best: {grid_result.best_score_} using {grid_result.best_params_}\")\r\n",
        "means = grid_result.cv_results_['mean_test_score']\r\n",
        "stds = grid_result.cv_results_['std_test_score']\r\n",
        "params = grid_result.cv_results_['params']\r\n",
        "for mean, stdev, param in zip(means, stds, params):\r\n",
        "    print(f\"Means: {mean}, Stdev: {stdev} with: {param}\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  \"timeout or by a memory leak.\", UserWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "2813/2813 [==============================] - 6s 2ms/step - loss: 1.5310 - accuracy: 0.4822\n",
            "Epoch 2/5\n",
            "2813/2813 [==============================] - 5s 2ms/step - loss: 0.7870 - accuracy: 0.7654\n",
            "Epoch 3/5\n",
            "2813/2813 [==============================] - 5s 2ms/step - loss: 0.6631 - accuracy: 0.8043\n",
            "Epoch 4/5\n",
            "2813/2813 [==============================] - 5s 2ms/step - loss: 0.6060 - accuracy: 0.8228\n",
            "Epoch 5/5\n",
            "2813/2813 [==============================] - 5s 2ms/step - loss: 0.5483 - accuracy: 0.8395\n",
            "Best: 0.8306111097335815 using {'batch_size': 32, 'epochs': 5, 'units': 128}\n",
            "Means: 0.8306111097335815, Stdev: 0.0041073570459400945 with: {'batch_size': 32, 'epochs': 5, 'units': 128}\n",
            "Means: 0.804022216796875, Stdev: 0.003870515641919862 with: {'batch_size': 64, 'epochs': 5, 'units': 128}\n",
            "Means: 0.7677666664123535, Stdev: 0.009403939213673062 with: {'batch_size': 128, 'epochs': 5, 'units': 128}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUHtKPJi3QAD"
      },
      "source": [
        "# Load the tensorboard extension\r\n",
        "%load_ext tensorboard"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "erhYN2xI3RBR"
      },
      "source": [
        "\r\n",
        "import tensorflow as tf\r\n",
        "from tensorboard.plugins.hparams import api as hp\r\n",
        "\r\n",
        "import os\r\n",
        "import datetime"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bctvM65P3U9u"
      },
      "source": [
        "\r\n",
        "HP_UNITS = hp.HParam('num_units', hp.Discrete([256, 64, 128]))\r\n",
        "HP_LR = hp.HParam('learning_rate', hp.RealInterval(0.01, 0.3))\r\n",
        "HP_OPT = hp.HParam('optimizer', hp.Discrete(['adam', 'adamax', 'sgd']))\r\n",
        "HP_LAYERS = hp.HParam('layers', hp.Discrete([1, 2, 3]))\r\n",
        "\r\n",
        "METRIC_ACCURACY = 'accuracy'\r\n",
        "\r\n",
        "with tf.summary.create_file_writer('logs/hp_tuning').as_default():\r\n",
        "    hp.hparams_config(\r\n",
        "        hparams=[HP_UNITS, HP_LR, HP_OPT, HP_LAYERS],\r\n",
        "        metrics=[hp.Metric(METRIC_ACCURACY, display_name='Accuracy')])"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GPtQPQI3ZaF"
      },
      "source": [
        "\r\n",
        "from tensorflow.keras.optimizers import Adamax\r\n",
        "\r\n",
        "def train_test_model(hparams):\r\n",
        "    model = Sequential([\r\n",
        "        Dense(hparams[HP_UNITS], activation='relu', input_dim=784),\r\n",
        "        Dense(hparams[HP_UNITS]/2, activation='relu'),\r\n",
        "        Dense(hparams[HP_UNITS]/4, activation='relu'),\r\n",
        "        Dense(10, activation='softmax')])\r\n",
        "\r\n",
        "    opt_name = hparams[HP_OPT]\r\n",
        "    lr = hparams[HP_LR]\r\n",
        "\r\n",
        "    if opt_name == 'sgd':\r\n",
        "        opt = tf.keras.optimizers.SGD(learning_rate=lr)\r\n",
        "    \r\n",
        "    elif opt_name == 'adam':\r\n",
        "        opt = tf.keras.optimizers.Adam(learning_rate=lr)\r\n",
        "    \r\n",
        "    elif opt_name == 'adamax':\r\n",
        "        opt = tf.keras.optimizers.Adamax(learning_rate=lr)\r\n",
        "    \r\n",
        "    else:\r\n",
        "        raise Exception(\"Unrecognized optimizer. Must be either 'sgd', 'adam' or 'adamax\")\r\n",
        "\r\n",
        "    model.compile(optimizer=opt,\r\n",
        "                  loss='sparse_categorical_crossentropy',\r\n",
        "                  metrics=['accuracy'])\r\n",
        "    \r\n",
        "    model.fit(X_train, y_train, \r\n",
        "              batch_size=32,\r\n",
        "              epochs=10)\r\n",
        "\r\n",
        "    _, val_acc = model.evaluate(X_test, y_test)\r\n",
        "\r\n",
        "    return val_acc"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9MiRBHpD3k6U"
      },
      "source": [
        "\r\n",
        "def run(run_dir, hparams):\r\n",
        "    with tf.summary.create_file_writer(run_dir).as_default():\r\n",
        "        hp.hparams(hparams)\r\n",
        "        accuracy = train_test_model(hparams)\r\n",
        "        tf.summary.scalar(METRIC_ACCURACY, accuracy, step=1)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SEe8auao3ptP",
        "outputId": "c8a2608b-fdb1-4bf6-e585-f5cc01822103"
      },
      "source": [
        "%%time\r\n",
        "session_num = 0 \r\n",
        "for num_units in HP_UNITS.domain.values:\r\n",
        "    for layer in HP_LAYERS.domain.values:\r\n",
        "        for learning_rate in tf.linspace(HP_LR.domain.min_value, \r\n",
        "                                        HP_LR.domain.max_value, num=3):\r\n",
        "            for optimizer in HP_OPT.domain.values:\r\n",
        "                hparams = {\r\n",
        "                    HP_UNITS: num_units,\r\n",
        "                    HP_LAYERS: layer,\r\n",
        "                    HP_LR: float(learning_rate),\r\n",
        "                    HP_OPT: optimizer\r\n",
        "                }\r\n",
        "        run_name = f\"run-{session_num}\"\r\n",
        "        print(f\"---> Starting trial: {run_name}\")\r\n",
        "        print({h.name: hparams[h] for h in hparams})\r\n",
        "        run('logs/hp_tuning/' + run_name, hparams)\r\n",
        "        session_num += 1"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "---> Starting trial: run-0\n",
            "{'num_units': 64, 'layers': 1, 'learning_rate': 0.30000001192092896, 'optimizer': 'sgd'}\n",
            "Epoch 1/10\n",
            "2813/2813 [==============================] - 5s 2ms/step - loss: 0.9366 - accuracy: 0.6965\n",
            "Epoch 2/10\n",
            "2813/2813 [==============================] - 5s 2ms/step - loss: 0.5632 - accuracy: 0.8267\n",
            "Epoch 3/10\n",
            "2813/2813 [==============================] - 5s 2ms/step - loss: 0.5044 - accuracy: 0.8472\n",
            "Epoch 4/10\n",
            "2813/2813 [==============================] - 5s 2ms/step - loss: 0.4677 - accuracy: 0.8595\n",
            "Epoch 5/10\n",
            "2813/2813 [==============================] - 5s 2ms/step - loss: 0.4529 - accuracy: 0.8629\n",
            "Epoch 6/10\n",
            "2813/2813 [==============================] - 5s 2ms/step - loss: 0.4323 - accuracy: 0.8711\n",
            "Epoch 7/10\n",
            "2813/2813 [==============================] - 5s 2ms/step - loss: 0.4213 - accuracy: 0.8752\n",
            "Epoch 8/10\n",
            "2813/2813 [==============================] - 5s 2ms/step - loss: 0.4070 - accuracy: 0.8803\n",
            "Epoch 9/10\n",
            "2813/2813 [==============================] - 5s 2ms/step - loss: 0.3959 - accuracy: 0.8829\n",
            "Epoch 10/10\n",
            "2813/2813 [==============================] - 5s 2ms/step - loss: 0.3890 - accuracy: 0.8849\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.6411 - accuracy: 0.8135\n",
            "---> Starting trial: run-1\n",
            "{'num_units': 64, 'layers': 2, 'learning_rate': 0.30000001192092896, 'optimizer': 'sgd'}\n",
            "Epoch 1/10\n",
            "2813/2813 [==============================] - 5s 2ms/step - loss: 0.9395 - accuracy: 0.6917\n",
            "Epoch 2/10\n",
            "2813/2813 [==============================] - 5s 2ms/step - loss: 0.5527 - accuracy: 0.8328\n",
            "Epoch 3/10\n",
            "2813/2813 [==============================] - 5s 2ms/step - loss: 0.5035 - accuracy: 0.8476\n",
            "Epoch 4/10\n",
            "2813/2813 [==============================] - 5s 2ms/step - loss: 0.4657 - accuracy: 0.8594\n",
            "Epoch 5/10\n",
            "2813/2813 [==============================] - 5s 2ms/step - loss: 0.4411 - accuracy: 0.8661\n",
            "Epoch 6/10\n",
            "2813/2813 [==============================] - 5s 2ms/step - loss: 0.4271 - accuracy: 0.8719\n",
            "Epoch 7/10\n",
            "2813/2813 [==============================] - 5s 2ms/step - loss: 0.4095 - accuracy: 0.8765\n",
            "Epoch 8/10\n",
            "2813/2813 [==============================] - 5s 2ms/step - loss: 0.4021 - accuracy: 0.8801\n",
            "Epoch 9/10\n",
            "2813/2813 [==============================] - 5s 2ms/step - loss: 0.3896 - accuracy: 0.8826\n",
            "Epoch 10/10\n",
            "2813/2813 [==============================] - 5s 2ms/step - loss: 0.3805 - accuracy: 0.8853\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.5418 - accuracy: 0.8504\n",
            "---> Starting trial: run-2\n",
            "{'num_units': 64, 'layers': 3, 'learning_rate': 0.30000001192092896, 'optimizer': 'sgd'}\n",
            "Epoch 1/10\n",
            "2813/2813 [==============================] - 5s 2ms/step - loss: 0.9318 - accuracy: 0.6971\n",
            "Epoch 2/10\n",
            "2813/2813 [==============================] - 5s 2ms/step - loss: 0.5528 - accuracy: 0.8324\n",
            "Epoch 3/10\n",
            "2813/2813 [==============================] - 5s 2ms/step - loss: 0.4908 - accuracy: 0.8528\n",
            "Epoch 4/10\n",
            "2813/2813 [==============================] - 5s 2ms/step - loss: 0.4604 - accuracy: 0.8600\n",
            "Epoch 5/10\n",
            "2813/2813 [==============================] - 5s 2ms/step - loss: 0.4403 - accuracy: 0.8685\n",
            "Epoch 6/10\n",
            "2813/2813 [==============================] - 5s 2ms/step - loss: 0.4266 - accuracy: 0.8706\n",
            "Epoch 7/10\n",
            "2813/2813 [==============================] - 5s 2ms/step - loss: 0.4083 - accuracy: 0.8772\n",
            "Epoch 8/10\n",
            "2813/2813 [==============================] - 5s 2ms/step - loss: 0.4011 - accuracy: 0.8781\n",
            "Epoch 9/10\n",
            "2813/2813 [==============================] - 5s 2ms/step - loss: 0.3847 - accuracy: 0.8841\n",
            "Epoch 10/10\n",
            "2813/2813 [==============================] - 5s 2ms/step - loss: 0.3823 - accuracy: 0.8864\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.5591 - accuracy: 0.8465\n",
            "---> Starting trial: run-3\n",
            "{'num_units': 128, 'layers': 1, 'learning_rate': 0.30000001192092896, 'optimizer': 'sgd'}\n",
            "Epoch 1/10\n",
            "2813/2813 [==============================] - 5s 2ms/step - loss: 0.8864 - accuracy: 0.7128\n",
            "Epoch 2/10\n",
            "2813/2813 [==============================] - 5s 2ms/step - loss: 0.5007 - accuracy: 0.8498\n",
            "Epoch 3/10\n",
            "2813/2813 [==============================] - 5s 2ms/step - loss: 0.4366 - accuracy: 0.8679\n",
            "Epoch 4/10\n",
            "2813/2813 [==============================] - 5s 2ms/step - loss: 0.3979 - accuracy: 0.8790\n",
            "Epoch 5/10\n",
            "2813/2813 [==============================] - 5s 2ms/step - loss: 0.3678 - accuracy: 0.8896\n",
            "Epoch 6/10\n",
            "2813/2813 [==============================] - 5s 2ms/step - loss: 0.3528 - accuracy: 0.8932\n",
            "Epoch 7/10\n",
            "2813/2813 [==============================] - 5s 2ms/step - loss: 0.3302 - accuracy: 0.8996\n",
            "Epoch 8/10\n",
            "2813/2813 [==============================] - 5s 2ms/step - loss: 0.3171 - accuracy: 0.9022\n",
            "Epoch 9/10\n",
            "2813/2813 [==============================] - 5s 2ms/step - loss: 0.3050 - accuracy: 0.9072\n",
            "Epoch 10/10\n",
            "2813/2813 [==============================] - 5s 2ms/step - loss: 0.2967 - accuracy: 0.9098\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.5390 - accuracy: 0.8513\n",
            "---> Starting trial: run-4\n",
            "{'num_units': 128, 'layers': 2, 'learning_rate': 0.30000001192092896, 'optimizer': 'sgd'}\n",
            "Epoch 1/10\n",
            "2813/2813 [==============================] - 5s 2ms/step - loss: 0.8835 - accuracy: 0.7149\n",
            "Epoch 2/10\n",
            "2813/2813 [==============================] - 5s 2ms/step - loss: 0.4996 - accuracy: 0.8491\n",
            "Epoch 3/10\n",
            "2813/2813 [==============================] - 5s 2ms/step - loss: 0.4333 - accuracy: 0.8669\n",
            "Epoch 4/10\n",
            "2813/2813 [==============================] - 5s 2ms/step - loss: 0.3937 - accuracy: 0.8794\n",
            "Epoch 5/10\n",
            "2813/2813 [==============================] - 5s 2ms/step - loss: 0.3662 - accuracy: 0.8863\n",
            "Epoch 6/10\n",
            "2813/2813 [==============================] - 5s 2ms/step - loss: 0.3464 - accuracy: 0.8952\n",
            "Epoch 7/10\n",
            "2813/2813 [==============================] - 5s 2ms/step - loss: 0.3283 - accuracy: 0.8991\n",
            "Epoch 8/10\n",
            "2813/2813 [==============================] - 5s 2ms/step - loss: 0.3142 - accuracy: 0.9024\n",
            "Epoch 9/10\n",
            "2813/2813 [==============================] - 5s 2ms/step - loss: 0.3009 - accuracy: 0.9091\n",
            "Epoch 10/10\n",
            "2813/2813 [==============================] - 5s 2ms/step - loss: 0.2881 - accuracy: 0.9120\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.5337 - accuracy: 0.8555\n",
            "---> Starting trial: run-5\n",
            "{'num_units': 128, 'layers': 3, 'learning_rate': 0.30000001192092896, 'optimizer': 'sgd'}\n",
            "Epoch 1/10\n",
            "2813/2813 [==============================] - 5s 2ms/step - loss: 0.8755 - accuracy: 0.7177\n",
            "Epoch 2/10\n",
            "2813/2813 [==============================] - 5s 2ms/step - loss: 0.5035 - accuracy: 0.8469\n",
            "Epoch 3/10\n",
            "2813/2813 [==============================] - 5s 2ms/step - loss: 0.4405 - accuracy: 0.8665\n",
            "Epoch 4/10\n",
            "2813/2813 [==============================] - 5s 2ms/step - loss: 0.4061 - accuracy: 0.8767\n",
            "Epoch 5/10\n",
            "2813/2813 [==============================] - 5s 2ms/step - loss: 0.3685 - accuracy: 0.8881\n",
            "Epoch 6/10\n",
            "2813/2813 [==============================] - 5s 2ms/step - loss: 0.3519 - accuracy: 0.8933\n",
            "Epoch 7/10\n",
            "2813/2813 [==============================] - 5s 2ms/step - loss: 0.3315 - accuracy: 0.8989\n",
            "Epoch 8/10\n",
            "2813/2813 [==============================] - 5s 2ms/step - loss: 0.3198 - accuracy: 0.9021\n",
            "Epoch 9/10\n",
            "2813/2813 [==============================] - 5s 2ms/step - loss: 0.3049 - accuracy: 0.9057\n",
            "Epoch 10/10\n",
            "2813/2813 [==============================] - 5s 2ms/step - loss: 0.2928 - accuracy: 0.9109\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.5529 - accuracy: 0.8549\n",
            "---> Starting trial: run-6\n",
            "{'num_units': 256, 'layers': 1, 'learning_rate': 0.30000001192092896, 'optimizer': 'sgd'}\n",
            "Epoch 1/10\n",
            "2813/2813 [==============================] - 5s 2ms/step - loss: 0.8366 - accuracy: 0.7302\n",
            "Epoch 2/10\n",
            "2813/2813 [==============================] - 5s 2ms/step - loss: 0.4618 - accuracy: 0.8586\n",
            "Epoch 3/10\n",
            "2813/2813 [==============================] - 5s 2ms/step - loss: 0.3978 - accuracy: 0.8770\n",
            "Epoch 4/10\n",
            "2813/2813 [==============================] - 5s 2ms/step - loss: 0.3473 - accuracy: 0.8931\n",
            "Epoch 5/10\n",
            "2813/2813 [==============================] - 5s 2ms/step - loss: 0.3217 - accuracy: 0.9004\n",
            "Epoch 6/10\n",
            "2813/2813 [==============================] - 5s 2ms/step - loss: 0.2919 - accuracy: 0.9089\n",
            "Epoch 7/10\n",
            "2813/2813 [==============================] - 5s 2ms/step - loss: 0.2600 - accuracy: 0.9202\n",
            "Epoch 8/10\n",
            "2813/2813 [==============================] - 5s 2ms/step - loss: 0.2465 - accuracy: 0.9236\n",
            "Epoch 9/10\n",
            "2813/2813 [==============================] - 5s 2ms/step - loss: 0.2358 - accuracy: 0.9256\n",
            "Epoch 10/10\n",
            "2813/2813 [==============================] - 5s 2ms/step - loss: 0.2154 - accuracy: 0.9327\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.5417 - accuracy: 0.8614\n",
            "---> Starting trial: run-7\n",
            "{'num_units': 256, 'layers': 2, 'learning_rate': 0.30000001192092896, 'optimizer': 'sgd'}\n",
            "Epoch 1/10\n",
            "2813/2813 [==============================] - 5s 2ms/step - loss: 0.8442 - accuracy: 0.7294\n",
            "Epoch 2/10\n",
            "2813/2813 [==============================] - 5s 2ms/step - loss: 0.4622 - accuracy: 0.8578\n",
            "Epoch 3/10\n",
            "2813/2813 [==============================] - 5s 2ms/step - loss: 0.3942 - accuracy: 0.8780\n",
            "Epoch 4/10\n",
            "2813/2813 [==============================] - 5s 2ms/step - loss: 0.3452 - accuracy: 0.8923\n",
            "Epoch 5/10\n",
            "2813/2813 [==============================] - 5s 2ms/step - loss: 0.3233 - accuracy: 0.9006\n",
            "Epoch 6/10\n",
            "2813/2813 [==============================] - 5s 2ms/step - loss: 0.2905 - accuracy: 0.9097\n",
            "Epoch 7/10\n",
            "2813/2813 [==============================] - 5s 2ms/step - loss: 0.2727 - accuracy: 0.9148\n",
            "Epoch 8/10\n",
            "2813/2813 [==============================] - 5s 2ms/step - loss: 0.2532 - accuracy: 0.9217\n",
            "Epoch 9/10\n",
            "2813/2813 [==============================] - 5s 2ms/step - loss: 0.2315 - accuracy: 0.9279\n",
            "Epoch 10/10\n",
            "2813/2813 [==============================] - 5s 2ms/step - loss: 0.2227 - accuracy: 0.9303\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.5525 - accuracy: 0.8660\n",
            "---> Starting trial: run-8\n",
            "{'num_units': 256, 'layers': 3, 'learning_rate': 0.30000001192092896, 'optimizer': 'sgd'}\n",
            "Epoch 1/10\n",
            "2813/2813 [==============================] - 5s 2ms/step - loss: 0.8344 - accuracy: 0.7315\n",
            "Epoch 2/10\n",
            "2813/2813 [==============================] - 5s 2ms/step - loss: 0.4613 - accuracy: 0.8591\n",
            "Epoch 3/10\n",
            "2813/2813 [==============================] - 5s 2ms/step - loss: 0.3921 - accuracy: 0.8786\n",
            "Epoch 4/10\n",
            "2813/2813 [==============================] - 5s 2ms/step - loss: 0.3553 - accuracy: 0.8901\n",
            "Epoch 5/10\n",
            "2813/2813 [==============================] - 5s 2ms/step - loss: 0.3116 - accuracy: 0.9026\n",
            "Epoch 6/10\n",
            "2813/2813 [==============================] - 5s 2ms/step - loss: 0.2904 - accuracy: 0.9106\n",
            "Epoch 7/10\n",
            "2813/2813 [==============================] - 5s 2ms/step - loss: 0.2709 - accuracy: 0.9150\n",
            "Epoch 8/10\n",
            "2813/2813 [==============================] - 5s 2ms/step - loss: 0.2557 - accuracy: 0.9203\n",
            "Epoch 9/10\n",
            "2813/2813 [==============================] - 5s 2ms/step - loss: 0.2352 - accuracy: 0.9262\n",
            "Epoch 10/10\n",
            "2813/2813 [==============================] - 5s 2ms/step - loss: 0.2193 - accuracy: 0.9316\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.5280 - accuracy: 0.8648\n",
            "CPU times: user 9min 2s, sys: 57.5 s, total: 10min\n",
            "Wall time: 7min 53s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NrYUp26Y3xVo"
      },
      "source": [
        "%tensorboard --logdir logs/hp_tuning"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LKbr1gRg9BXs"
      },
      "source": [
        "### Stretch Goals\n",
        "- Implement Bayesian Hyper-parameter Optimization\n",
        "- Select a new dataset and apply a neural network to it.\n",
        "- Use a cloud base experiment tracking framework such as weights and biases\n",
        "- Research potential architecture ideas for this problem. Try Lenet-10 for example. "
      ]
    }
  ]
}